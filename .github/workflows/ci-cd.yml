name: CI/CD Pipeline

on:
  push:
    branches: [ "main" ]
  pull_request:
    branches: [ "main" ]

env:
  AWS_REGION: ap-south-1
  PYTHONPATH: ${{ github.workspace }}

  # ECR Repositories
  ECR_BACKEND: resume-backend
  ECR_FRONTEND: resume-frontend
  ECR_GRAFANA: resume-grafana
  ECR_PROMETHEUS: resume-prometheus

  # ECS Configuration
  ECS_CLUSTER: resume-cluster
  ECS_SERVICE: resume-service
  ECS_TASK_DEFINITION: resume-tasks

jobs:
  # ------------------------------------------------------------------
  # JOB 1: QUALITY ASSURANCE (The Gatekeeper)
  # ------------------------------------------------------------------
  quality-assurance:
    runs-on: ubuntu-latest
    # These secrets are required for Integration Tests to talk to RDS/Neo4j
    env:
      DB_HOST: ${{ secrets.DB_HOST }}
      DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
      DB_USER: postgres
      DB_NAME: postgres
      DB_PORT: 5432
      GROQ_API_KEY: ${{ secrets.GROQ_API_KEY }} 
      NEO4J_URI: ${{ secrets.NEO4J_URI }}
      NEO4J_PASSWORD: ${{ secrets.NEO4J_PASSWORD }}

    steps:
      - name: Checkout Code
        uses: actions/checkout@v4

      - name: Set up Python 3.11
        uses: actions/setup-python@v4
        with:
          python-version: "3.11"

      - name: Configure AWS Credentials (for DVC/S3)
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Install Dependencies & DVC
        # DVC needs credentials to pull artifacts
        env:
          AWS_ACCESS_KEY_ID: ${{ secrets.AWS_ACCESS_KEY_ID }}
          AWS_SECRET_ACCESS_KEY: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        run: |
          python -m pip install --upgrade pip
          pip install flake8 pytest pytest-mock httpx "dvc[s3]"
          
          # Install App Dependencies
          if [ -f requirements-backend.txt ]; then pip install -r requirements-backend.txt; fi
          if [ -f requirements-frontend.txt ]; then pip install -r requirements-frontend.txt; fi
          
          # CI OPTIMIZATION: Only pull lightweight artifacts (NLTK) for tests.
          # We SKIP the heavy ML models here to save time/bandwidth.
          # Your Unit/Smoke tests should mock the model logic.
          dvc pull artifacts/nltk_data.dvc

      - name: Linting (Flake8)
        run: |
          flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics
          flake8 . --count --exit-zero --max-complexity=10 --max-line-length=127 --statistics

      - name: Run Unit Tests
        run: pytest tests/unit

      - name: Run Smoke Tests
        run: pytest tests/smoke

      # ⚠️ UNCOMMENT THESE ONLY IF YOU ADDED DB SECRETS TO GITHUB
      # - name: Run Integration Tests
      #   run: pytest tests/integration
      
      # - name: Run Regression Tests
      #   run: pytest tests/regression

  # ------------------------------------------------------------------
  # JOB 2: DEPLOYMENT (Runs only if QA Passes)
  # ------------------------------------------------------------------
  deploy:
    needs: quality-assurance
    if: github.ref == 'refs/heads/main' && github.event_name == 'push'
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: ${{ env.AWS_REGION }}

      - name: Login to Amazon ECR
        id: login-ecr
        uses: aws-actions/amazon-ecr-login@v2

      - name: Install jq
        run: sudo apt-get update && sudo apt-get install -y jq

      # HYDRATION: Now we pull EVERYTHING (including heavy models) for the Docker Image
      - name: Install DVC & Pull Full Models
        run: |
          python -m pip install --upgrade pip
          pip install "dvc[s3]"
          dvc pull models/all-mpnet-base-v2.dvc artifacts/nltk_data.dvc

      # --- BUILD & PUSH (4 IMAGES) ---
      - name: Build & Push Backend
        id: build-backend
        run: |
          docker build -f Dockerfile.backend \
            -t ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_BACKEND }}:${{ github.sha }} .
          docker push ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_BACKEND }}:${{ github.sha }}
          echo "image=${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_BACKEND }}:${{ github.sha }}" >> $GITHUB_OUTPUT

      - name: Build & Push Frontend
        id: build-frontend
        run: |
          docker build -f Dockerfile.frontend \
            -t ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_FRONTEND }}:${{ github.sha }} .
          docker push ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_FRONTEND }}:${{ github.sha }}
          echo "image=${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_FRONTEND }}:${{ github.sha }}" >> $GITHUB_OUTPUT

      - name: Build & Push Prometheus
        id: build-prometheus
        run: |
          docker build -f Dockerfile.prometheus \
            -t ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_PROMETHEUS }}:${{ github.sha }} .
          docker push ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_PROMETHEUS }}:${{ github.sha }}
          echo "image=${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_PROMETHEUS }}:${{ github.sha }}" >> $GITHUB_OUTPUT

      - name: Build & Push Grafana
        id: build-grafana
        run: |
          docker build -f Dockerfile.grafana \
            -t ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_GRAFANA }}:${{ github.sha }} .
          docker push ${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_GRAFANA }}:${{ github.sha }}
          echo "image=${{ steps.login-ecr.outputs.registry }}/${{ env.ECR_GRAFANA }}:${{ github.sha }}" >> $GITHUB_OUTPUT

      # --- UPDATE ECS ---
      - name: Download ECS task definition
        run: |
          aws ecs describe-task-definition \
            --task-definition ${{ env.ECS_TASK_DEFINITION }} \
            --query taskDefinition > task-def.json

          jq 'del(
            .taskDefinitionArn, .revision, .status, .requiresAttributes, .compatibilities, 
            .registeredAt, .registeredBy, .enableFaultInjection
          )' task-def.json > cleaned-task-def.json

      # Render Chain: Backend -> Frontend -> Prom -> Grafana -> Final JSON
      - name: Render Backend Image
        id: render-backend
        uses: aws-actions/amazon-ecs-render-task-definition@v1
        with:
          task-definition: cleaned-task-def.json
          container-name: backend
          image: ${{ steps.build-backend.outputs.image }}

      - name: Render Frontend Image
        id: render-frontend
        uses: aws-actions/amazon-ecs-render-task-definition@v1
        with:
          task-definition: ${{ steps.render-backend.outputs.task-definition }}
          container-name: frontend
          image: ${{ steps.build-frontend.outputs.image }}

      - name: Render Prometheus Image
        id: render-prometheus
        uses: aws-actions/amazon-ecs-render-task-definition@v1
        with:
          task-definition: ${{ steps.render-frontend.outputs.task-definition }}
          container-name: prometheus
          image: ${{ steps.build-prometheus.outputs.image }}

      - name: Render Grafana Image
        id: render-grafana
        uses: aws-actions/amazon-ecs-render-task-definition@v1
        with:
          task-definition: ${{ steps.render-prometheus.outputs.task-definition }}
          container-name: grafana
          image: ${{ steps.build-grafana.outputs.image }}

      - name: Deploy to ECS Service
        uses: aws-actions/amazon-ecs-deploy-task-definition@v1
        with:
          task-definition: ${{ steps.render-grafana.outputs.task-definition }}
          service: ${{ env.ECS_SERVICE }}
          cluster: ${{ env.ECS_CLUSTER }}
          wait-for-service-stability: true