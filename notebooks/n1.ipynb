{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def list_files(startpath):\n",
    "    # Folders to skip to keep output readable\n",
    "    skip_dirs = {'.git', '.dvc', 'venv311', '__pycache__', '.ipynb_checkpoints'}\n",
    "    \n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        # Filter out skipped directories\n",
    "        dirs[:] = [d for d in dirs if d not in skip_dirs]\n",
    "        \n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print(f'{indent}{os.path.basename(root)}/')\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            print(f'{subindent}{f}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Current Structure for: {os.getcwd()}\\n\")\n",
    "    list_files('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic path test \n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Fix the path logic so the Notebook can see the 'utils' folder\n",
    "# This assumes your notebook is in a subfolder. If it's in the root, use \".\"\n",
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "\n",
    "try:\n",
    "    from utils.paths import (\n",
    "        BASE_DIR, \n",
    "        RAW_SERPAPI_DIR, \n",
    "        PROCESSED_SERPAPI_DIR, \n",
    "        LOG_DIR, \n",
    "        JOBS_CSV_PATH, \n",
    "        LOCATIONS_YAML_PATH, \n",
    "        PARAMS_PATH\n",
    "    )\n",
    "\n",
    "    # 2. Define the paths to check\n",
    "    paths_to_check = {\n",
    "        \"Project Root (BASE_DIR)\": BASE_DIR,\n",
    "        \"Raw Data Folder\": RAW_SERPAPI_DIR,\n",
    "        \"Processed Data Folder\": PROCESSED_SERPAPI_DIR,\n",
    "        \"Logs Folder\": LOG_DIR,\n",
    "        \"Jobs CSV File\": JOBS_CSV_PATH,\n",
    "        \"Locations YAML File\": LOCATIONS_YAML_PATH,\n",
    "        \"Global paramas file \": PARAMS_PATH\n",
    "    }\n",
    "\n",
    "    # 3. Perform Validation\n",
    "    results = []\n",
    "    for name, path in paths_to_check.items():\n",
    "        results.append({\n",
    "            \"Component\": name,\n",
    "            \"Exists\": \"‚úÖ Yes\" if path.exists() else \"‚ùå NO\",\n",
    "            \"Type\": \"Directory\" if path.is_dir() else \"File\" if path.is_file() else \"Missing\",\n",
    "            \"Absolute Path\": str(path.resolve())\n",
    "        })\n",
    "\n",
    "    # 4. Display as a nice Table\n",
    "    df_results = pd.DataFrame(results)\n",
    "    display(df_results)\n",
    "\n",
    "    # 5. Summary Warning\n",
    "    missing_count = sum(1 for r in results if \"‚ùå\" in r[\"Exists\"])\n",
    "    if missing_count > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è WARNING: {missing_count} path(s) are invalid. Check your BASE_DIR in utils/paths.py!\")\n",
    "    else:\n",
    "        print(\"\\nüöÄ ALL SYSTEM PATHS ARE VALID!\")\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "    print(\"‚ùå ERROR: Could not find 'utils' folder. Ensure you are running the notebook from the correct directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Fix the path logic so the Notebook can see the 'utils' folder\n",
    "# This assumes your notebook is in a subfolder. If it's in the root, use \".\"\n",
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "\n",
    "\n",
    "from utils.paths import (\n",
    "        BASE_DIR, \n",
    "        RAW_SERPAPI_DIR, \n",
    "        PROCESSED_SERPAPI_DIR, \n",
    "        LOG_DIR, \n",
    "        JOBS_CSV_PATH, \n",
    "        LOCATIONS_YAML_PATH\n",
    ")\n",
    "\n",
    "print(BASE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from utils.paths import get_processed_data_path\n",
    "from utils.dates import current_run_month\n",
    "\n",
    "# 1. Load your latest processed data\n",
    "csv_path = get_processed_data_path(current_run_month())\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 2. Define the placeholders we used in process_data.py\n",
    "placeholders = [\"Unknown\", \"Not mentioned\", \"None\"]\n",
    "\n",
    "# 3. Create the report\n",
    "report_data = []\n",
    "\n",
    "for col in df.columns:\n",
    "    # Standard NaNs\n",
    "    nan_count = df[col].isnull().sum()\n",
    "    \n",
    "    # Placeholder counts (Unknown, etc.)\n",
    "    placeholder_count = df[col].astype(str).isin(placeholders).sum()\n",
    "    \n",
    "    total_missing = nan_count + placeholder_count\n",
    "    \n",
    "    report_data.append({\n",
    "        \"Column\": col,\n",
    "        \"Actual NaN\": nan_count,\n",
    "        \"Placeholders\": placeholder_count,\n",
    "        \"Total Missing\": total_missing,\n",
    "        \"Usability %\": round(((len(df) - total_missing) / len(df)) * 100, 2)\n",
    "    })\n",
    "\n",
    "# 4. Display as a clean DataFrame\n",
    "quality_report = pd.DataFrame(report_data).set_index(\"Column\")\n",
    "\n",
    "print(f\"--- Data Quality Heartbeat: {current_run_month()} ---\")\n",
    "print(quality_report.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow.sklearn\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Use the direct Run URI instead of the Model Name\n",
    "# This points exactly to the folder we saw in your DagsHub screenshot\n",
    "RUN_ID = \"8f0a412b5b5948118a307b38818ef430\"\n",
    "DIRECT_URI = f\"runs:/{RUN_ID}/job_categorizer_model\"\n",
    "\n",
    "print(f\"üì° Pulling direct from Run: {RUN_ID}...\")\n",
    "\n",
    "try:\n",
    "    # 2. Load the pipeline\n",
    "    loaded_pipeline = mlflow.sklearn.load_model(DIRECT_URI)\n",
    "    print(\"‚úÖ Success! Model loaded from direct run path.\")\n",
    "\n",
    "    # 3. Quick Test\n",
    "    sample_text = [\"Senior LLM Engineer with experience in LangChain and PyTorch\"]\n",
    "    prediction = loaded_pipeline.predict(sample_text)\n",
    "    print(f\"üèÜ Sample Prediction: {prediction[0]}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Direct Load Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import mlflow\n",
    "\n",
    "os.environ[\"MLFLOW_TRACKING_USERNAME\"] = \"Akashthakur0326\"\n",
    "os.environ[\"MLFLOW_TRACKING_PASSWORD\"] = \"d2a8af2664d554a5366508dd80f33e027eb377c2\"\n",
    "\n",
    "mlflow.set_tracking_uri(\"https://dagshub.com/Akashthakur0326/ResumeRecommender-MLops.mlflow\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
