{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1a8a3c1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Structure for: c:\\Users\\Admin\\Desktop\\ResumeRecommenderMLops\\notebooks\n",
      "\n",
      "../\n",
      "    .dvcignore\n",
      "    .env\n",
      "    .gitignore\n",
      "    dvc.lock\n",
      "    dvc.yaml\n",
      "    params.yaml\n",
      "    pyproject.toml\n",
      "    README.md\n",
      "    requirements.txt\n",
      "    status.txt\n",
      "    .github/\n",
      "        workflows/\n",
      "            serpapi_data_ingestion.yml\n",
      "    app/\n",
      "    artifacts/\n",
      "    data/\n",
      "        constants/\n",
      "            jobs.csv\n",
      "            locations.yaml\n",
      "        processed/\n",
      "        raw/\n",
      "            serpapi/\n",
      "                2026-01/\n",
      "                    AI_Engineer_Bengaluru_India_page41.json\n",
      "                    AI_Engineer_Chennai_India_page44.json\n",
      "                    AI_Engineer_Delhi_India_page45.json\n",
      "                    AI_Engineer_Hyderabad_India_page42.json\n",
      "                    AI_Engineer_Pune_India_page43.json\n",
      "                    Analytics_Engineer_Bengaluru_India_page83.json\n",
      "                    Analytics_Engineer_Chennai_India_page86.json\n",
      "                    Analytics_Engineer_Hyderabad_India_page84.json\n",
      "                    Analytics_Engineer_Pune_India_page85.json\n",
      "                    Android_Developer_Bengaluru_India_page108.json\n",
      "                    Android_Developer_Hyderabad_India_page109.json\n",
      "                    Android_Developer_Pune_India_page110.json\n",
      "                    Applied_Machine_Learning_Engineer_Bengaluru_India_page67.json\n",
      "                    Applied_Machine_Learning_Engineer_Chennai_India_page70.json\n",
      "                    Applied_Machine_Learning_Engineer_Hyderabad_India_page68.json\n",
      "                    Applied_Machine_Learning_Engineer_Pune_India_page69.json\n",
      "                    AR_VR_Engineer_Bengaluru_India_page138.json\n",
      "                    AR_VR_Engineer_Hyderabad_India_page139.json\n",
      "                    AR_VR_Engineer_Pune_India_page140.json\n",
      "                    Automation_Test_Engineer_Bengaluru_India_page129.json\n",
      "                    Automation_Test_Engineer_Hyderabad_India_page130.json\n",
      "                    Automation_Test_Engineer_Pune_India_page131.json\n",
      "                    Backend_Engineer_Bengaluru_India_page11.json\n",
      "                    Backend_Engineer_Chennai_India_page14.json\n",
      "                    Backend_Engineer_Delhi_India_page15.json\n",
      "                    Backend_Engineer_Hyderabad_India_page12.json\n",
      "                    Backend_Engineer_Pune_India_page13.json\n",
      "                    Cloud_Engineer_Bengaluru_India_page59.json\n",
      "                    Cloud_Engineer_Chennai_India_page62.json\n",
      "                    Cloud_Engineer_Hyderabad_India_page60.json\n",
      "                    Cloud_Engineer_Pune_India_page61.json\n",
      "                    Computer_Vision_Engineer_Bengaluru_India_page75.json\n",
      "                    Computer_Vision_Engineer_Chennai_India_page78.json\n",
      "                    Computer_Vision_Engineer_Hyderabad_India_page76.json\n",
      "                    Computer_Vision_Engineer_Pune_India_page77.json\n",
      "                    Cybersecurity_Engineer_Bengaluru_India_page114.json\n",
      "                    Cybersecurity_Engineer_Hyderabad_India_page115.json\n",
      "                    Cybersecurity_Engineer_Pune_India_page116.json\n",
      "                    Database_Engineer_Bengaluru_India_page99.json\n",
      "                    Database_Engineer_Hyderabad_India_page100.json\n",
      "                    Database_Engineer_Pune_India_page101.json\n",
      "                    Data_Analyst_Bengaluru_India_page31.json\n",
      "                    Data_Analyst_Chennai_India_page34.json\n",
      "                    Data_Analyst_Delhi_India_page35.json\n",
      "                    Data_Analyst_Hyderabad_India_page32.json\n",
      "                    Data_Analyst_Pune_India_page33.json\n",
      "                    Data_Engineer_Bengaluru_India_page36.json\n",
      "                    Data_Engineer_Chennai_India_page39.json\n",
      "                    Data_Engineer_Delhi_India_page40.json\n",
      "                    Data_Engineer_Hyderabad_India_page37.json\n",
      "                    Data_Engineer_Pune_India_page38.json\n",
      "                    Data_Scientist_Bengaluru_India_page21.json\n",
      "                    Data_Scientist_Chennai_India_page24.json\n",
      "                    Data_Scientist_Delhi_India_page25.json\n",
      "                    Data_Scientist_Hyderabad_India_page22.json\n",
      "                    Data_Scientist_Pune_India_page23.json\n",
      "                    Deep_Learning_Engineer_Bengaluru_India_page91.json\n",
      "                    Deep_Learning_Engineer_Chennai_India_page94.json\n",
      "                    Deep_Learning_Engineer_Hyderabad_India_page92.json\n",
      "                    Deep_Learning_Engineer_Pune_India_page93.json\n",
      "                    DevOps_Engineer_Bengaluru_India_page51.json\n",
      "                    DevOps_Engineer_Chennai_India_page54.json\n",
      "                    DevOps_Engineer_Hyderabad_India_page52.json\n",
      "                    DevOps_Engineer_Pune_India_page53.json\n",
      "                    Embedded_Systems_Engineer_Bengaluru_India_page120.json\n",
      "                    Embedded_Systems_Engineer_Hyderabad_India_page121.json\n",
      "                    Embedded_Systems_Engineer_Pune_India_page122.json\n",
      "                    Firmware_Engineer_Bengaluru_India_page123.json\n",
      "                    Firmware_Engineer_Hyderabad_India_page124.json\n",
      "                    Firmware_Engineer_Pune_India_page125.json\n",
      "                    Frontend_Developer_Bengaluru_India_page46.json\n",
      "                    Frontend_Developer_Chennai_India_page49.json\n",
      "                    Frontend_Developer_Delhi_India_page50.json\n",
      "                    Frontend_Developer_Hyderabad_India_page47.json\n",
      "                    Frontend_Developer_Pune_India_page48.json\n",
      "                    Full_Stack_Developer_Bengaluru_India_page16.json\n",
      "                    Full_Stack_Developer_Chennai_India_page19.json\n",
      "                    Full_Stack_Developer_Delhi_India_page20.json\n",
      "                    Full_Stack_Developer_Hyderabad_India_page17.json\n",
      "                    Full_Stack_Developer_Pune_India_page18.json\n",
      "                    Game_Developer_Bengaluru_India_page135.json\n",
      "                    Game_Developer_Hyderabad_India_page136.json\n",
      "                    Game_Developer_Pune_India_page137.json\n",
      "                    Graphics_Programmer_Bengaluru_India_page141.json\n",
      "                    Graphics_Programmer_Hyderabad_India_page142.json\n",
      "                    Graphics_Programmer_Pune_India_page143.json\n",
      "                    iOS_Developer_Bengaluru_India_page111.json\n",
      "                    iOS_Developer_Hyderabad_India_page112.json\n",
      "                    iOS_Developer_Pune_India_page113.json\n",
      "                    Machine_Learning_Engineer_Bengaluru_India_page26.json\n",
      "                    Machine_Learning_Engineer_Chennai_India_page29.json\n",
      "                    Machine_Learning_Engineer_Delhi_India_page30.json\n",
      "                    Machine_Learning_Engineer_Hyderabad_India_page27.json\n",
      "                    Machine_Learning_Engineer_Pune_India_page28.json\n",
      "                    MLOps_Engineer_Bengaluru_India_page55.json\n",
      "                    MLOps_Engineer_Chennai_India_page58.json\n",
      "                    MLOps_Engineer_Hyderabad_India_page56.json\n",
      "                    MLOps_Engineer_Pune_India_page57.json\n",
      "                    ML_Research_Engineer_Bengaluru_India_page95.json\n",
      "                    ML_Research_Engineer_Chennai_India_page98.json\n",
      "                    ML_Research_Engineer_Hyderabad_India_page96.json\n",
      "                    ML_Research_Engineer_Pune_India_page97.json\n",
      "                    Mobile_Application_Developer_Bengaluru_India_page105.json\n",
      "                    Mobile_Application_Developer_Hyderabad_India_page106.json\n",
      "                    Mobile_Application_Developer_Pune_India_page107.json\n",
      "                    NLP_Engineer_Bengaluru_India_page71.json\n",
      "                    NLP_Engineer_Chennai_India_page74.json\n",
      "                    NLP_Engineer_Hyderabad_India_page72.json\n",
      "                    NLP_Engineer_Pune_India_page73.json\n",
      "                    Platform_Engineer_Bengaluru_India_page79.json\n",
      "                    Platform_Engineer_Chennai_India_page82.json\n",
      "                    Platform_Engineer_Hyderabad_India_page80.json\n",
      "                    Platform_Engineer_Pune_India_page81.json\n",
      "                    Product_Engineer_Bengaluru_India_page150.json\n",
      "                    Product_Engineer_Hyderabad_India_page151.json\n",
      "                    Product_Engineer_Pune_India_page152.json\n",
      "                    QA_Engineer_Bengaluru_India_page126.json\n",
      "                    QA_Engineer_Hyderabad_India_page127.json\n",
      "                    QA_Engineer_Pune_India_page128.json\n",
      "                    Research_Scientist_Bengaluru_India_page87.json\n",
      "                    Research_Scientist_Chennai_India_page90.json\n",
      "                    Research_Scientist_Hyderabad_India_page88.json\n",
      "                    Research_Scientist_Pune_India_page89.json\n",
      "                    SDET_Bengaluru_India_page132.json\n",
      "                    SDET_Hyderabad_India_page133.json\n",
      "                    SDET_Pune_India_page134.json\n",
      "                    Security_Engineer_Bengaluru_India_page117.json\n",
      "                    Security_Engineer_Hyderabad_India_page118.json\n",
      "                    Security_Engineer_Pune_India_page119.json\n",
      "                    Site_Reliability_Engineer_Bengaluru_India_page63.json\n",
      "                    Site_Reliability_Engineer_Chennai_India_page66.json\n",
      "                    Site_Reliability_Engineer_Hyderabad_India_page64.json\n",
      "                    Site_Reliability_Engineer_Pune_India_page65.json\n",
      "                    Software_Developer_Bengaluru_India_page6.json\n",
      "                    Software_Developer_Chennai_India_page9.json\n",
      "                    Software_Developer_Delhi_India_page10.json\n",
      "                    Software_Developer_Hyderabad_India_page7.json\n",
      "                    Software_Developer_Pune_India_page8.json\n",
      "                    Software_Engineer_Bengaluru_India_page1.json\n",
      "                    Software_Engineer_Chennai_India_page4.json\n",
      "                    Software_Engineer_Delhi_India_page5.json\n",
      "                    Software_Engineer_Hyderabad_India_page2.json\n",
      "                    Software_Engineer_Pune_India_page3.json\n",
      "                    Solutions_Engineer_Bengaluru_India_page147.json\n",
      "                    Solutions_Engineer_Hyderabad_India_page148.json\n",
      "                    Solutions_Engineer_Pune_India_page149.json\n",
      "                    SQL_Developer_Bengaluru_India_page102.json\n",
      "                    SQL_Developer_Hyderabad_India_page103.json\n",
      "                    SQL_Developer_Pune_India_page104.json\n",
      "                    Technical_Product_Manager_Bengaluru_India_page144.json\n",
      "                    Technical_Product_Manager_Hyderabad_India_page145.json\n",
      "                    Technical_Product_Manager_Pune_India_page146.json\n",
      "    data_ingestion/\n",
      "        jd_ingestion/\n",
      "            bright_data/\n",
      "            serp_api/\n",
      "                priority_scheduler.py\n",
      "                serpapi_client.py\n",
      "                serpapi_ingest.py\n",
      "        resume_ingestion/\n",
      "            docx_ingest.py\n",
      "            image_ingest.py\n",
      "            pdf_ingest.py\n",
      "    db/\n",
      "    infra/\n",
      "    logs/\n",
      "        serpapi/\n",
      "            2026-01.log\n",
      "    ml/\n",
      "    notebooks/\n",
      "        n1.ipynb\n",
      "    prompts/\n",
      "        job_description_KB.txt\n",
      "    resume_recommender_mlops.egg-info/\n",
      "        dependency_links.txt\n",
      "        PKG-INFO\n",
      "        requires.txt\n",
      "        SOURCES.txt\n",
      "        top_level.txt\n",
      "    scripts/\n",
      "    ui/\n",
      "    utils/\n",
      "        dates.py\n",
      "        logger.py\n",
      "        paths.py\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def list_files(startpath):\n",
    "    # Folders to skip to keep output readable\n",
    "    skip_dirs = {'.git', '.dvc', 'venv311', '__pycache__', '.ipynb_checkpoints'}\n",
    "    \n",
    "    for root, dirs, files in os.walk(startpath):\n",
    "        # Filter out skipped directories\n",
    "        dirs[:] = [d for d in dirs if d not in skip_dirs]\n",
    "        \n",
    "        level = root.replace(startpath, '').count(os.sep)\n",
    "        indent = ' ' * 4 * (level)\n",
    "        print(f'{indent}{os.path.basename(root)}/')\n",
    "        subindent = ' ' * 4 * (level + 1)\n",
    "        for f in files:\n",
    "            print(f'{subindent}{f}')\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(f\"Current Structure for: {os.getcwd()}\\n\")\n",
    "    list_files('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b2e0a78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hi\n"
     ]
    }
   ],
   "source": [
    "print(\"hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12b26324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Component</th>\n",
       "      <th>Exists</th>\n",
       "      <th>Type</th>\n",
       "      <th>Absolute Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Project Root (BASE_DIR)</td>\n",
       "      <td>‚úÖ Yes</td>\n",
       "      <td>Directory</td>\n",
       "      <td>C:\\Users\\Admin\\Desktop\\ResumeRecommenderMLops</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Raw Data Folder</td>\n",
       "      <td>‚úÖ Yes</td>\n",
       "      <td>Directory</td>\n",
       "      <td>C:\\Users\\Admin\\Desktop\\ResumeRecommenderMLops\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Processed Data Folder</td>\n",
       "      <td>‚úÖ Yes</td>\n",
       "      <td>Directory</td>\n",
       "      <td>C:\\Users\\Admin\\Desktop\\ResumeRecommenderMLops\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logs Folder</td>\n",
       "      <td>‚úÖ Yes</td>\n",
       "      <td>Directory</td>\n",
       "      <td>C:\\Users\\Admin\\Desktop\\ResumeRecommenderMLops\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jobs CSV File</td>\n",
       "      <td>‚úÖ Yes</td>\n",
       "      <td>File</td>\n",
       "      <td>C:\\Users\\Admin\\Desktop\\ResumeRecommenderMLops\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Locations YAML File</td>\n",
       "      <td>‚úÖ Yes</td>\n",
       "      <td>File</td>\n",
       "      <td>C:\\Users\\Admin\\Desktop\\ResumeRecommenderMLops\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Global paramas file</td>\n",
       "      <td>‚úÖ Yes</td>\n",
       "      <td>File</td>\n",
       "      <td>C:\\Users\\Admin\\Desktop\\ResumeRecommenderMLops\\...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Component Exists       Type  \\\n",
       "0  Project Root (BASE_DIR)  ‚úÖ Yes  Directory   \n",
       "1          Raw Data Folder  ‚úÖ Yes  Directory   \n",
       "2    Processed Data Folder  ‚úÖ Yes  Directory   \n",
       "3              Logs Folder  ‚úÖ Yes  Directory   \n",
       "4            Jobs CSV File  ‚úÖ Yes       File   \n",
       "5      Locations YAML File  ‚úÖ Yes       File   \n",
       "6     Global paramas file   ‚úÖ Yes       File   \n",
       "\n",
       "                                       Absolute Path  \n",
       "0      C:\\Users\\Admin\\Desktop\\ResumeRecommenderMLops  \n",
       "1  C:\\Users\\Admin\\Desktop\\ResumeRecommenderMLops\\...  \n",
       "2  C:\\Users\\Admin\\Desktop\\ResumeRecommenderMLops\\...  \n",
       "3  C:\\Users\\Admin\\Desktop\\ResumeRecommenderMLops\\...  \n",
       "4  C:\\Users\\Admin\\Desktop\\ResumeRecommenderMLops\\...  \n",
       "5  C:\\Users\\Admin\\Desktop\\ResumeRecommenderMLops\\...  \n",
       "6  C:\\Users\\Admin\\Desktop\\ResumeRecommenderMLops\\...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üöÄ ALL SYSTEM PATHS ARE VALID!\n"
     ]
    }
   ],
   "source": [
    "#basic path test \n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Fix the path logic so the Notebook can see the 'utils' folder\n",
    "# This assumes your notebook is in a subfolder. If it's in the root, use \".\"\n",
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "\n",
    "try:\n",
    "    from utils.paths import (\n",
    "        BASE_DIR, \n",
    "        RAW_SERPAPI_DIR, \n",
    "        PROCESSED_SERPAPI_DIR, \n",
    "        LOG_DIR, \n",
    "        JOBS_CSV_PATH, \n",
    "        LOCATIONS_YAML_PATH, \n",
    "        PARAMS_PATH\n",
    "    )\n",
    "\n",
    "    # 2. Define the paths to check\n",
    "    paths_to_check = {\n",
    "        \"Project Root (BASE_DIR)\": BASE_DIR,\n",
    "        \"Raw Data Folder\": RAW_SERPAPI_DIR,\n",
    "        \"Processed Data Folder\": PROCESSED_SERPAPI_DIR,\n",
    "        \"Logs Folder\": LOG_DIR,\n",
    "        \"Jobs CSV File\": JOBS_CSV_PATH,\n",
    "        \"Locations YAML File\": LOCATIONS_YAML_PATH,\n",
    "        \"Global paramas file \": PARAMS_PATH\n",
    "    }\n",
    "\n",
    "    # 3. Perform Validation\n",
    "    results = []\n",
    "    for name, path in paths_to_check.items():\n",
    "        results.append({\n",
    "            \"Component\": name,\n",
    "            \"Exists\": \"‚úÖ Yes\" if path.exists() else \"‚ùå NO\",\n",
    "            \"Type\": \"Directory\" if path.is_dir() else \"File\" if path.is_file() else \"Missing\",\n",
    "            \"Absolute Path\": str(path.resolve())\n",
    "        })\n",
    "\n",
    "    # 4. Display as a nice Table\n",
    "    df_results = pd.DataFrame(results)\n",
    "    display(df_results)\n",
    "\n",
    "    # 5. Summary Warning\n",
    "    missing_count = sum(1 for r in results if \"‚ùå\" in r[\"Exists\"])\n",
    "    if missing_count > 0:\n",
    "        print(f\"\\n‚ö†Ô∏è WARNING: {missing_count} path(s) are invalid. Check your BASE_DIR in utils/paths.py!\")\n",
    "    else:\n",
    "        print(\"\\nüöÄ ALL SYSTEM PATHS ARE VALID!\")\n",
    "\n",
    "except ModuleNotFoundError:\n",
    "    print(\"‚ùå ERROR: Could not find 'utils' folder. Ensure you are running the notebook from the correct directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2558d8c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\Desktop\\ResumeRecommenderMLops\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Fix the path logic so the Notebook can see the 'utils' folder\n",
    "# This assumes your notebook is in a subfolder. If it's in the root, use \".\"\n",
    "sys.path.append(os.path.abspath(\"..\")) \n",
    "\n",
    "\n",
    "from utils.paths import (\n",
    "        BASE_DIR, \n",
    "        RAW_SERPAPI_DIR, \n",
    "        PROCESSED_SERPAPI_DIR, \n",
    "        LOG_DIR, \n",
    "        JOBS_CSV_PATH, \n",
    "        LOCATIONS_YAML_PATH\n",
    ")\n",
    "\n",
    "print(BASE_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cf90e8b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Data Quality Heartbeat: 2026-01 ---\n",
      "                     Actual NaN  Placeholders  Total Missing  Usability %\n",
      "Column                                                                   \n",
      "job_id                        0             0              0       100.00\n",
      "title                         0             0              0       100.00\n",
      "company_name                  0             0              0       100.00\n",
      "location                      0             1              1        99.89\n",
      "description                   0             0              0       100.00\n",
      "salary                        0           835            835         8.24\n",
      "schedule_type                 0             1              1        99.89\n",
      "posted_at                     0           292            292        67.91\n",
      "search_term                   0             0              0       100.00\n",
      "search_location               0             0              0       100.00\n",
      "ingestion_month               0             0              0       100.00\n",
      "ingestion_timestamp           0             0              0       100.00\n",
      "data_source                   0             0              0       100.00\n",
      "search_engine                 0             0              0       100.00\n",
      "llm_based_category            0           910            910         0.00\n",
      "job_link                      0             0              0       100.00\n",
      "apply_link                    0             0              0       100.00\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from utils.paths import get_processed_data_path\n",
    "from utils.dates import current_run_month\n",
    "\n",
    "# 1. Load your latest processed data\n",
    "csv_path = get_processed_data_path(current_run_month())\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "# 2. Define the placeholders we used in process_data.py\n",
    "placeholders = [\"Unknown\", \"Not mentioned\", \"None\"]\n",
    "\n",
    "# 3. Create the report\n",
    "report_data = []\n",
    "\n",
    "for col in df.columns:\n",
    "    # Standard NaNs\n",
    "    nan_count = df[col].isnull().sum()\n",
    "    \n",
    "    # Placeholder counts (Unknown, etc.)\n",
    "    placeholder_count = df[col].astype(str).isin(placeholders).sum()\n",
    "    \n",
    "    total_missing = nan_count + placeholder_count\n",
    "    \n",
    "    report_data.append({\n",
    "        \"Column\": col,\n",
    "        \"Actual NaN\": nan_count,\n",
    "        \"Placeholders\": placeholder_count,\n",
    "        \"Total Missing\": total_missing,\n",
    "        \"Usability %\": round(((len(df) - total_missing) / len(df)) * 100, 2)\n",
    "    })\n",
    "\n",
    "# 4. Display as a clean DataFrame\n",
    "quality_report = pd.DataFrame(report_data).set_index(\"Column\")\n",
    "\n",
    "print(f\"--- Data Quality Heartbeat: {current_run_month()} ---\")\n",
    "print(quality_report.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d97f9456",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_id</th>\n",
       "      <th>title</th>\n",
       "      <th>company_name</th>\n",
       "      <th>location</th>\n",
       "      <th>description</th>\n",
       "      <th>salary</th>\n",
       "      <th>schedule_type</th>\n",
       "      <th>posted_at</th>\n",
       "      <th>search_term</th>\n",
       "      <th>search_location</th>\n",
       "      <th>ingestion_month</th>\n",
       "      <th>ingestion_timestamp</th>\n",
       "      <th>data_source</th>\n",
       "      <th>search_engine</th>\n",
       "      <th>llm_based_category</th>\n",
       "      <th>job_link</th>\n",
       "      <th>apply_link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCBJSUkgLS...</td>\n",
       "      <td>Data Scientist III - Pricing Analytics</td>\n",
       "      <td>Expedia Group</td>\n",
       "      <td>Gurugram, Haryana</td>\n",
       "      <td>Expedia Group brands power global travel for e...</td>\n",
       "      <td>Not mentioned</td>\n",
       "      <td>Full‚Äìtime</td>\n",
       "      <td>3 days ago</td>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurugram, India</td>\n",
       "      <td>2026-01</td>\n",
       "      <td>2026-01-22 19:08:02 UTC</td>\n",
       "      <td>serpapi</td>\n",
       "      <td>google_jobs</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>https://www.google.com/search?ibp=htl;jobs&amp;q=D...</td>\n",
       "      <td>https://in.linkedin.com/jobs/view/data-scienti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJQcmFjdGljZSBNYW5hZ2VyIOKAky...</td>\n",
       "      <td>Practice Manager ‚Äì Data Engineering</td>\n",
       "      <td>Lagozon Technologies Pvt. Ltd</td>\n",
       "      <td>New Delhi, Delhi</td>\n",
       "      <td>As a Practice Manager in Data Engineering, you...</td>\n",
       "      <td>Not mentioned</td>\n",
       "      <td>Full‚Äìtime</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>Data Engineer</td>\n",
       "      <td>Noida, India</td>\n",
       "      <td>2026-01</td>\n",
       "      <td>2026-01-22 19:11:44 UTC</td>\n",
       "      <td>serpapi</td>\n",
       "      <td>google_jobs</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>https://www.google.com/search?ibp=htl;jobs&amp;q=D...</td>\n",
       "      <td>https://www.lagozon.com/job/practice-manager-d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>425</th>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJHZW5lcmF0aXZlIEFJIEVuZ2luZW...</td>\n",
       "      <td>Generative AI Engineer</td>\n",
       "      <td>Turing</td>\n",
       "      <td>Gandhinagar, Gujarat</td>\n",
       "      <td>About the role: Turing is looking for people w...</td>\n",
       "      <td>Not mentioned</td>\n",
       "      <td>Full‚Äìtime</td>\n",
       "      <td>10 days ago</td>\n",
       "      <td>Generative AI Engineer</td>\n",
       "      <td>Ahmedabad, India</td>\n",
       "      <td>2026-01</td>\n",
       "      <td>2026-01-22 19:09:54 UTC</td>\n",
       "      <td>serpapi</td>\n",
       "      <td>google_jobs</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>https://www.google.com/search?ibp=htl;jobs&amp;q=G...</td>\n",
       "      <td>https://getmereferred.com/job-listing/generati...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJTdGFmZiBCYWNrZW5kIEVuZ2luZW...</td>\n",
       "      <td>Staff Backend Engineer</td>\n",
       "      <td>Tide</td>\n",
       "      <td>New Delhi, Delhi</td>\n",
       "      <td>ABOUT TIDE At Tide we help SMEs save time (and...</td>\n",
       "      <td>Not mentioned</td>\n",
       "      <td>Full‚Äìtime</td>\n",
       "      <td>7 days ago</td>\n",
       "      <td>Backend Engineer</td>\n",
       "      <td>New Delhi, India</td>\n",
       "      <td>2026-01</td>\n",
       "      <td>2026-01-22 19:06:38 UTC</td>\n",
       "      <td>serpapi</td>\n",
       "      <td>google_jobs</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>https://www.google.com/search?ibp=htl;jobs&amp;q=B...</td>\n",
       "      <td>https://builtindelhi.in/job/staff-backend-engi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QgSW50ZXJuIi...</td>\n",
       "      <td>Data Analyst Intern</td>\n",
       "      <td>Opkey</td>\n",
       "      <td>Noida, Uttar Pradesh</td>\n",
       "      <td>Opkey | Series B Funded | Noida (In-Office) | ...</td>\n",
       "      <td>Not mentioned</td>\n",
       "      <td>Internship</td>\n",
       "      <td>21 days ago</td>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Noida, India</td>\n",
       "      <td>2026-01</td>\n",
       "      <td>2026-01-22 19:11:04 UTC</td>\n",
       "      <td>serpapi</td>\n",
       "      <td>google_jobs</td>\n",
       "      <td>Unknown</td>\n",
       "      <td>https://www.google.com/search?ibp=htl;jobs&amp;q=D...</td>\n",
       "      <td>https://nextleap.app/jobs/data-analyst/data-an...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                job_id  \\\n",
       "259  eyJqb2JfdGl0bGUiOiJEYXRhIFNjaWVudGlzdCBJSUkgLS...   \n",
       "567  eyJqb2JfdGl0bGUiOiJQcmFjdGljZSBNYW5hZ2VyIOKAky...   \n",
       "425  eyJqb2JfdGl0bGUiOiJHZW5lcmF0aXZlIEFJIEVuZ2luZW...   \n",
       "866  eyJqb2JfdGl0bGUiOiJTdGFmZiBCYWNrZW5kIEVuZ2luZW...   \n",
       "156  eyJqb2JfdGl0bGUiOiJEYXRhIEFuYWx5c3QgSW50ZXJuIi...   \n",
       "\n",
       "                                      title                   company_name  \\\n",
       "259  Data Scientist III - Pricing Analytics                  Expedia Group   \n",
       "567     Practice Manager ‚Äì Data Engineering  Lagozon Technologies Pvt. Ltd   \n",
       "425                  Generative AI Engineer                         Turing   \n",
       "866                  Staff Backend Engineer                           Tide   \n",
       "156                     Data Analyst Intern                          Opkey   \n",
       "\n",
       "                 location                                        description  \\\n",
       "259     Gurugram, Haryana  Expedia Group brands power global travel for e...   \n",
       "567      New Delhi, Delhi  As a Practice Manager in Data Engineering, you...   \n",
       "425  Gandhinagar, Gujarat  About the role: Turing is looking for people w...   \n",
       "866      New Delhi, Delhi  ABOUT TIDE At Tide we help SMEs save time (and...   \n",
       "156  Noida, Uttar Pradesh  Opkey | Series B Funded | Noida (In-Office) | ...   \n",
       "\n",
       "            salary schedule_type    posted_at             search_term  \\\n",
       "259  Not mentioned     Full‚Äìtime   3 days ago          Data Scientist   \n",
       "567  Not mentioned     Full‚Äìtime      Unknown           Data Engineer   \n",
       "425  Not mentioned     Full‚Äìtime  10 days ago  Generative AI Engineer   \n",
       "866  Not mentioned     Full‚Äìtime   7 days ago        Backend Engineer   \n",
       "156  Not mentioned    Internship  21 days ago            Data Analyst   \n",
       "\n",
       "      search_location ingestion_month      ingestion_timestamp data_source  \\\n",
       "259   Gurugram, India         2026-01  2026-01-22 19:08:02 UTC     serpapi   \n",
       "567      Noida, India         2026-01  2026-01-22 19:11:44 UTC     serpapi   \n",
       "425  Ahmedabad, India         2026-01  2026-01-22 19:09:54 UTC     serpapi   \n",
       "866  New Delhi, India         2026-01  2026-01-22 19:06:38 UTC     serpapi   \n",
       "156      Noida, India         2026-01  2026-01-22 19:11:04 UTC     serpapi   \n",
       "\n",
       "    search_engine llm_based_category  \\\n",
       "259   google_jobs            Unknown   \n",
       "567   google_jobs            Unknown   \n",
       "425   google_jobs            Unknown   \n",
       "866   google_jobs            Unknown   \n",
       "156   google_jobs            Unknown   \n",
       "\n",
       "                                              job_link  \\\n",
       "259  https://www.google.com/search?ibp=htl;jobs&q=D...   \n",
       "567  https://www.google.com/search?ibp=htl;jobs&q=D...   \n",
       "425  https://www.google.com/search?ibp=htl;jobs&q=G...   \n",
       "866  https://www.google.com/search?ibp=htl;jobs&q=B...   \n",
       "156  https://www.google.com/search?ibp=htl;jobs&q=D...   \n",
       "\n",
       "                                            apply_link  \n",
       "259  https://in.linkedin.com/jobs/view/data-scienti...  \n",
       "567  https://www.lagozon.com/job/practice-manager-d...  \n",
       "425  https://getmereferred.com/job-listing/generati...  \n",
       "866  https://builtindelhi.in/job/staff-backend-engi...  \n",
       "156  https://nextleap.app/jobs/data-analyst/data-an...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605057d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
