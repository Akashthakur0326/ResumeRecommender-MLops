{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2H0RUoBRW8Rt",
    "outputId": "2802386e-38d0-481f-8abb-3f2072b17edf"
   },
   "outputs": [],
   "source": [
    "from google import genai\n",
    "from google.colab import userdata\n",
    "\n",
    "api_key = userdata.get('gemini_key')\n",
    "\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    contents=\"sup\"\n",
    ")\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0cp4x-lZXE00"
   },
   "outputs": [],
   "source": [
    "!pip install \"dvc[gdrive]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "id": "53Ck4HlsXE8m",
    "outputId": "8cd9ba51-67b7-4076-ae60-e1824b52f126"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"/content/drive/Othercomputers/My laptop/Desktop/ResumeRecommenderMLops/data/processed/serpapi/2026-01\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4dvCBqVaKfgL",
    "outputId": "a366f4d3-e885-4334-833b-8500c39780bb"
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZnxxHVhZD_lW"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import time\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from google.colab import userdata\n",
    "from tqdm import tqdm\n",
    "\n",
    "api_key = userdata.get('gemini_key')\n",
    "client = genai.Client(api_key=api_key)\n",
    "\n",
    "CATEGORIES = [\n",
    "    \"Software Engineer\", \"Software Developer\", \"Backend Engineer\", \"Full Stack Developer\",\n",
    "    \"Data Scientist\", \"Machine Learning Engineer\", \"Generative AI Engineer\", \"LLM Engineer\",\n",
    "    \"Data Analyst\", \"Data Engineer\", \"AI Engineer\", \"Frontend Developer\", \"React Developer\",\n",
    "    \"Python Developer\", \"Java Developer\", \"DevOps Engineer\", \"MLOps Engineer\", \"Cloud Engineer\",\n",
    "    \"Cloud Security Engineer\", \"Kubernetes Administrator\", \"Site Reliability Engineer\",\n",
    "    \"Applied Machine Learning Engineer\", \"NLP Engineer\", \"Computer Vision Engineer\",\n",
    "    \"Platform Engineer\", \"Analytics Engineer\", \"Data Architect\", \"Research Scientist\",\n",
    "    \"Deep Learning Engineer\", \"ML Research Engineer\", \"FinOps Engineer\", \"Database Engineer\",\n",
    "    \"SQL Developer\", \"Business Intelligence Engineer\", \"Mobile Application Developer\",\n",
    "    \"Android Developer\", \"iOS Developer\", \"Cybersecurity Engineer\", \"Security Engineer\",\n",
    "    \"Embedded Systems Engineer\", \"Firmware Engineer\", \"QA Engineer\", \"Automation Test Engineer\",\n",
    "    \"SDET\", \"Game Developer\", \"AR/VR Engineer\", \"Graphics Programmer\", \"Technical Product Manager\",\n",
    "    \"Solutions Engineer\", \"Product Engineer\", \"Blockchain Developer\", \"RPA Developer\",\n",
    "    \"Salesforce Developer\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "eMz97kbxXE-h"
   },
   "outputs": [],
   "source": [
    "def classify_batch_v2(batch_df, model_name=\"gemini-2.5-flash\"):\n",
    "    # 1. Prepare minimal input (ID + Title + Description)\n",
    "    # We use the DataFrame index as the ID for the model to map back\n",
    "    jobs_text = \"\"\n",
    "    for idx, row in batch_df.iterrows():\n",
    "        # Truncate description to 500 chars to save tokens/speed\n",
    "        desc = str(row['description'])[:500].replace(\"\\n\", \" \")\n",
    "        jobs_text += f\"ID: {idx} | Title: {row['title']} | Desc: {desc}\\n\"\n",
    "\n",
    "    # 2. Define the Schema (The structure we want back)\n",
    "    # We want a dictionary where keys are strings (IDs) and values are strings (Categories)\n",
    "    # Note: In JSON, keys must be strings.\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert job classifier.\n",
    "    Classify the following 100 jobs into exactly ONE of these categories:\n",
    "    {json.dumps(CATEGORIES)}\n",
    "\n",
    "    Instructions:\n",
    "    - Return a JSON dictionary where the key is the Job ID provided and the value is the Category.\n",
    "    - Use 'Other' if the job doesn't match any category.\n",
    "    - Output format: {{ \"849\": \"Data Analyst\", \"277\": \"Data Engineer\", ... }}\n",
    "\n",
    "    Jobs to Classify:\n",
    "    {jobs_text}\n",
    "    \"\"\"\n",
    "\n",
    "    # 3. Call the Model with Structured Output Config\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=model_name,\n",
    "            contents=prompt,\n",
    "            config=types.GenerateContentConfig(\n",
    "                response_mime_type=\"application/json\",\n",
    "                # We specify strict JSON output\n",
    "            )\n",
    "        )\n",
    "        return json.loads(response.text)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in batch: {e}\")\n",
    "        return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_l6Nmx-uXE_W",
    "outputId": "bfa830f4-af98-4294-a889-a618826036ca"
   },
   "outputs": [],
   "source": [
    "# Create a copy to work on\n",
    "df_labeled = df.copy()\n",
    "\n",
    "if 'llm_based_category' not in df_labeled.columns:\n",
    "    df_labeled['llm_based_category'] = None\n",
    "df_labeled['llm_based_category'] = df_labeled['llm_based_category'].astype(object)\n",
    "\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "print(f\"Starting classification of {len(df_labeled)} jobs in batches of {BATCH_SIZE}...\")\n",
    "\n",
    "for i in tqdm(range(0, len(df_labeled), BATCH_SIZE)):\n",
    "    # 1. Slice the batch\n",
    "    batch = df_labeled.iloc[i : i + BATCH_SIZE]\n",
    "\n",
    "    # 2. Call Gemini\n",
    "    # Note: Ensure you use a valid model name. 'gemini-2.0-flash' is the standard.\n",
    "    # If 'gemini-2.5-flash' is available to you, use that.\n",
    "    results_dict = classify_batch_v2(batch, model_name=\"gemini-2.5-flash\")\n",
    "\n",
    "    # 3. Fill the DataFrame\n",
    "    # The dictionary keys are the INDICES of the dataframe (as strings)\n",
    "    for idx_str, category in results_dict.items():\n",
    "        try:\n",
    "            # Convert string key back to integer index if your DF index is int\n",
    "            idx = int(idx_str)\n",
    "            df_labeled.at[idx, 'llm_based_category'] = category\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to map index {idx_str}: {e}\")\n",
    "\n",
    "    # Sleep to respect rate limits (optional with 2.0 Flash as it's very fast)\n",
    "    time.sleep(2)\n",
    "\n",
    "# 4. Save\n",
    "df_labeled.to_csv(\"labeled_jobs_100_batch.csv\", index=False)\n",
    "print(\"Done! Saved to labeled_jobs_100_batch.csv\")\n",
    "\n",
    "# 5. Check missing\n",
    "missing = df_labeled['llm_based_category'].isnull().sum()\n",
    "print(f\"Jobs left unclassified: {missing}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 625
    },
    "id": "NPwGrAhRXFAa",
    "outputId": "2eae3ced-6fa9-4250-f644-102dbab360cf"
   },
   "outputs": [],
   "source": [
    "df_labeled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-sIV8CqXFCP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Choose your target path in Drive\n",
    "save_directory = \"/content/drive/Othercomputers/My laptop/Desktop/ResumeRecommenderMLops/data/processed/serpapi\"\n",
    "save_filename = \"labeled_jobs.csv\"\n",
    "save_path = os.path.join(save_directory, save_filename)\n",
    "\n",
    "# Make sure the folder exists\n",
    "os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "\n",
    "# Save dataframe\n",
    "df_labeled.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NxfXP2Y2XDir"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "from google import genai\n",
    "from google.colab import userdata\n",
    "from IPython.display import display, JSON\n",
    "\n",
    "# --- 1. CONFIGURATION & DATA ---\n",
    "\n",
    "# The full list of categories\n",
    "CATEGORIES = [\n",
    "    \"Software Engineer\", \"Software Developer\", \"Backend Engineer\", \"Full Stack Developer\",\n",
    "    \"Data Scientist\", \"Machine Learning Engineer\", \"Generative AI Engineer\", \"LLM Engineer\",\n",
    "    \"Data Analyst\", \"Data Engineer\", \"AI Engineer\", \"Frontend Developer\", \"React Developer\",\n",
    "    \"Python Developer\", \"Java Developer\", \"DevOps Engineer\", \"MLOps Engineer\", \"Cloud Engineer\",\n",
    "    \"Cloud Security Engineer\", \"Kubernetes Administrator\", \"Site Reliability Engineer\",\n",
    "    \"Applied Machine Learning Engineer\", \"NLP Engineer\", \"Computer Vision Engineer\",\n",
    "    \"Platform Engineer\", \"Analytics Engineer\", \"Data Architect\", \"Research Scientist\",\n",
    "    \"Deep Learning Engineer\", \"ML Research Engineer\", \"FinOps Engineer\", \"Database Engineer\",\n",
    "    \"SQL Developer\", \"Business Intelligence Engineer\", \"Mobile Application Developer\",\n",
    "    \"Android Developer\", \"iOS Developer\", \"Cybersecurity Engineer\", \"Security Engineer\",\n",
    "    \"Embedded Systems Engineer\", \"Firmware Engineer\", \"QA Engineer\", \"Automation Test Engineer\",\n",
    "    \"SDET\", \"Game Developer\", \"AR/VR Engineer\", \"Graphics Programmer\", \"Technical Product Manager\",\n",
    "    \"Solutions Engineer\", \"Product Engineer\", \"Blockchain Developer\", \"RPA Developer\",\n",
    "    \"Salesforce Developer\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OeGNREYmXDqY"
   },
   "outputs": [],
   "source": [
    "# The Reference JSON Structure (Minified for prompt efficiency)\n",
    "JSON_TEMPLATE = \"\"\"\n",
    "{\n",
    "  \"job_title\": \"String\",\n",
    "  \"role_category\": \"String\",\n",
    "  \"role_level\": [\"Junior\", \"Mid\", \"Senior\"],\n",
    "  \"role_summary\": \"Detailed description string\",\n",
    "  \"primary_responsibilities\": [\"List of strings\"],\n",
    "  \"technical_skills\": {\n",
    "    \"frontend\": [], \"backend\": [], \"databases\": [], \"version_control\": [], \"deployment\": []\n",
    "  },\n",
    "  \"programming_languages\": [\"List of strings\"],\n",
    "  \"frameworks_and_libraries\": [\"List of strings\"],\n",
    "  \"tools_and_platforms\": [\"List of strings\"],\n",
    "  \"non_technical_skills\": [\"List of strings\"],\n",
    "  \"educational_background\": { \"preferred_degree\": [], \"degree_required\": boolean },\n",
    "  \"experience_requirements\": { \"junior\": \"String\", \"mid\": \"String\", \"senior\": \"String\" },\n",
    "  \"common_projects\": [\"List of strings\"],\n",
    "  \"interview_topics\": [\"List of strings\"],\n",
    "  \"common_tools_in_interviews\": [\"List of strings\"],\n",
    "  \"career_progression\": [\"List of strings\"],\n",
    "  \"related_roles\": [\"List of strings\"],\n",
    "  \"industry_domains\": [\"List of strings\"],\n",
    "  \"salary_range_in_india\": { \"junior\": \"String\", \"mid\": \"String\", \"senior\": \"String\" },\n",
    "  \"resume_keywords\": [\"List of strings\"],\n",
    "  \"skill_taxonomy\": { \"must_have\": [], \"good_to_have\": [], \"domain_specific\": [] },\n",
    "  \"complexity_signals\": { \"high_impact_keywords\": [], \"valuable_certifications\": [] },\n",
    "  \"alternative_titles\": [\"List of strings\"]\n",
    "}\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "x3M1TyWHXDs-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "F5UOr8RWXDvX"
   },
   "outputs": [],
   "source": [
    "def setup_client():\n",
    "    \"\"\"Initializes the Gemini client using Colab userdata.\"\"\"\n",
    "    try:\n",
    "        api_key = userdata.get('gemini_key')\n",
    "        return genai.Client(api_key=api_key)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: Could not retrieve API key. Make sure 'gemini_key' is set in Colab secrets. \\nDetails: {e}\")\n",
    "        return None\n",
    "\n",
    "def clean_json_response(response_text):\n",
    "    \"\"\"\n",
    "    Cleans the model response to extract the JSON list.\n",
    "    Removes Markdown code fences (```json ... ```).\n",
    "    \"\"\"\n",
    "    cleaned_text = response_text.strip()\n",
    "    if cleaned_text.startswith(\"```json\"):\n",
    "        cleaned_text = cleaned_text[7:]\n",
    "    if cleaned_text.startswith(\"```\"):\n",
    "        cleaned_text = cleaned_text[3:]\n",
    "    if cleaned_text.endswith(\"```\"):\n",
    "        cleaned_text = cleaned_text[:-3]\n",
    "    return cleaned_text.strip()\n",
    "\n",
    "def process_batch(client, batch_titles, template):\n",
    "    \"\"\"\n",
    "    Sends a batch of titles to Gemini and requests a detailed JSON list.\n",
    "    \"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert technical recruiter and engineering manager.\n",
    "    I will provide a list of job titles. For EACH title, generate a DETAILED JSON object following the exact structure provided below.\n",
    "\n",
    "    CRITICAL INSTRUCTIONS:\n",
    "    1. Return a valid JSON List `[...]` containing one object for every title in the input list.\n",
    "    2. Do not omit any fields. Fill arrays with at least 5-7 relevant items.\n",
    "    3. Ensure technical accuracy (e.g., dont list React as a skill for an Embedded Engineer).\n",
    "    4. Return ONLY the JSON. No conversational text.\n",
    "\n",
    "    ### INPUT JOB TITLES:\n",
    "    {json.dumps(batch_titles)}\n",
    "\n",
    "    ### REQUIRED JSON STRUCTURE:\n",
    "    {template}\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        response = client.models.generate_content(\n",
    "            model=\"gemini-2.5-flash\", # Using 2.0 Flash for speed/cost or Pro for quality\n",
    "            contents=prompt,\n",
    "            config={\"response_mime_type\": \"application/json\"} # Enforce JSON mode\n",
    "        )\n",
    "        return json.loads(clean_json_response(response.text))\n",
    "    except Exception as e:\n",
    "        print(f\"‚ö†Ô∏è Error processing batch {batch_titles}: {e}\")\n",
    "        return []\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TK-NV5NOXDyJ",
    "outputId": "1ca79f38-c040-4ff7-bcce-29780b0c2005"
   },
   "outputs": [],
   "source": [
    "# --- 3. MAIN EXECUTION LOOP ---\n",
    "\n",
    "def main():\n",
    "    client = setup_client()\n",
    "    if not client: return\n",
    "\n",
    "    BATCH_SIZE = 10\n",
    "    all_job_descriptions = []\n",
    "\n",
    "    total_categories = len(CATEGORIES)\n",
    "    print(f\"üöÄ Starting generation for {total_categories} categories...\")\n",
    "\n",
    "    for i in range(0, total_categories, BATCH_SIZE):\n",
    "        batch = CATEGORIES[i : i + BATCH_SIZE]\n",
    "        print(f\"   Processing batch {i//BATCH_SIZE + 1}: {batch[0]} ... {batch[-1]}\")\n",
    "\n",
    "        # Call the API\n",
    "        batch_results = process_batch(client, batch, JSON_TEMPLATE)\n",
    "\n",
    "        if batch_results:\n",
    "            all_job_descriptions.extend(batch_results)\n",
    "            print(f\"   ‚úÖ Successfully generated {len(batch_results)} roles.\")\n",
    "        else:\n",
    "            print(\"   ‚ùå Failed to generate batch.\")\n",
    "\n",
    "        # Respect rate limits (optional, but good practice)\n",
    "        time.sleep(2)\n",
    "\n",
    "    # --- 4. SAVE OUTPUT ---\n",
    "    output_filename = \"detailed_job_descriptions.json\"\n",
    "    with open(output_filename, \"w\") as f:\n",
    "        json.dump(all_job_descriptions, f, indent=2)\n",
    "\n",
    "    print(f\"\\nüéâ Completed! Generated {len(all_job_descriptions)} descriptions.\")\n",
    "    print(f\"üìÅ Data saved to '{output_filename}'\")\n",
    "\n",
    "    # Optional: Preview first item\n",
    "    if all_job_descriptions:\n",
    "        print(\"\\n--- Preview of first item ---\")\n",
    "        print(json.dumps(all_job_descriptions[0], indent=2))\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jFuEG4NJXD0z"
   },
   "outputs": [],
   "source": [
    "source_file = \"detailed_job_descriptions.json\"\n",
    "\n",
    "# Your target directory on Drive\n",
    "target_dir = \"/content/drive/Othercomputers/My laptop/Desktop/ResumeRecommenderMLops/data/constants/KB\"\n",
    "target_file = os.path.join(target_dir, \"detailed_job_descriptions.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WCo9sd8iXfea",
    "outputId": "8e6bf9a8-d5e9-4888-b54c-1032fadf41e4"
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "if not os.path.exists(target_dir):\n",
    "    print(f\"üìÇ Creating directory: {target_dir}\")\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "# 4. Check if the source file exists (from the previous run)\n",
    "if os.path.exists(source_file):\n",
    "    print(f\"üöö Moving file from Colab runtime to Drive...\")\n",
    "\n",
    "    # Copy the file\n",
    "    shutil.copy2(source_file, target_file)\n",
    "\n",
    "    print(f\"‚úÖ Success! File saved to: {target_file}\")\n",
    "\n",
    "    # Verify file size to ensure it's not empty\n",
    "    size = os.path.getsize(target_file)\n",
    "    print(f\"üìä File size: {size / 1024:.2f} KB\")\n",
    "\n",
    "else:\n",
    "    print(f\"‚ùå Error: Could not find '{source_file}' in the current directory.\")\n",
    "    print(\"Please make sure the generation script has finished running completely before running this cell.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xtlJnzXUYyb2"
   },
   "source": [
    "PROCESSING MISSING PARTS OF THE FILLED JSON IN CASE SOME CATEGORIES ARE MISSING WE GO THROUGH THE JSON AND REFILL IT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gv-3G0KsYl1E",
    "outputId": "9817d7c8-e6d2-483c-b341-8c09e73fcb37"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import time\n",
    "import os\n",
    "import random\n",
    "from google import genai\n",
    "from google.colab import userdata\n",
    "from google.colab import drive\n",
    "\n",
    "# --- 1. SETUP & PATHS ---\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Exact path you provided\n",
    "SAVE_DIR = \"/content/drive/Othercomputers/My laptop/Desktop/ResumeRecommenderMLops/data/constants/KB\"\n",
    "FILE_PATH = os.path.join(SAVE_DIR, \"detailed_job_descriptions.json\")\n",
    "\n",
    "# The Master List\n",
    "ALL_CATEGORIES = [\n",
    "    \"Software Engineer\", \"Software Developer\", \"Backend Engineer\", \"Full Stack Developer\",\n",
    "    \"Data Scientist\", \"Machine Learning Engineer\", \"Generative AI Engineer\", \"LLM Engineer\",\n",
    "    \"Data Analyst\", \"Data Engineer\", \"AI Engineer\", \"Frontend Developer\", \"React Developer\",\n",
    "    \"Python Developer\", \"Java Developer\", \"DevOps Engineer\", \"MLOps Engineer\", \"Cloud Engineer\",\n",
    "    \"Cloud Security Engineer\", \"Kubernetes Administrator\", \"Site Reliability Engineer\",\n",
    "    \"Applied Machine Learning Engineer\", \"NLP Engineer\", \"Computer Vision Engineer\",\n",
    "    \"Platform Engineer\", \"Analytics Engineer\", \"Data Architect\", \"Research Scientist\",\n",
    "    \"Deep Learning Engineer\", \"ML Research Engineer\", \"FinOps Engineer\", \"Database Engineer\",\n",
    "    \"SQL Developer\", \"Business Intelligence Engineer\", \"Mobile Application Developer\",\n",
    "    \"Android Developer\", \"iOS Developer\", \"Cybersecurity Engineer\", \"Security Engineer\",\n",
    "    \"Embedded Systems Engineer\", \"Firmware Engineer\", \"QA Engineer\", \"Automation Test Engineer\",\n",
    "    \"SDET\", \"Game Developer\", \"AR/VR Engineer\", \"Graphics Programmer\", \"Technical Product Manager\",\n",
    "    \"Solutions Engineer\", \"Product Engineer\", \"Blockchain Developer\", \"RPA Developer\",\n",
    "    \"Salesforce Developer\"\n",
    "]\n",
    "\n",
    "JSON_TEMPLATE = \"\"\"\n",
    "{\n",
    "  \"job_title\": \"String\",\n",
    "  \"role_category\": \"String\",\n",
    "  \"role_level\": [\"Junior\", \"Mid\", \"Senior\"],\n",
    "  \"role_summary\": \"Detailed description string\",\n",
    "  \"primary_responsibilities\": [\"List of strings\"],\n",
    "  \"technical_skills\": {\n",
    "    \"frontend\": [], \"backend\": [], \"databases\": [], \"version_control\": [], \"deployment\": []\n",
    "  },\n",
    "  \"programming_languages\": [\"List of strings\"],\n",
    "  \"frameworks_and_libraries\": [\"List of strings\"],\n",
    "  \"tools_and_platforms\": [\"List of strings\"],\n",
    "  \"non_technical_skills\": [\"List of strings\"],\n",
    "  \"educational_background\": { \"preferred_degree\": [], \"degree_required\": boolean },\n",
    "  \"experience_requirements\": { \"junior\": \"String\", \"mid\": \"String\", \"senior\": \"String\" },\n",
    "  \"common_projects\": [\"List of strings\"],\n",
    "  \"interview_topics\": [\"List of strings\"],\n",
    "  \"common_tools_in_interviews\": [\"List of strings\"],\n",
    "  \"career_progression\": [\"List of strings\"],\n",
    "  \"related_roles\": [\"List of strings\"],\n",
    "  \"industry_domains\": [\"List of strings\"],\n",
    "  \"salary_range_in_india\": { \"junior\": \"String\", \"mid\": \"String\", \"senior\": \"String\" },\n",
    "  \"resume_keywords\": [\"List of strings\"],\n",
    "  \"skill_taxonomy\": { \"must_have\": [], \"good_to_have\": [], \"domain_specific\": [] },\n",
    "  \"complexity_signals\": { \"high_impact_keywords\": [], \"valuable_certifications\": [] },\n",
    "  \"alternative_titles\": [\"List of strings\"]\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# --- 2. HELPER FUNCTIONS ---\n",
    "\n",
    "def clean_json_response(response_text):\n",
    "    text = response_text.strip()\n",
    "    if text.startswith(\"```json\"): text = text[7:]\n",
    "    if text.startswith(\"```\"): text = text[3:]\n",
    "    if text.endswith(\"```\"): text = text[:-3]\n",
    "    return text.strip()\n",
    "\n",
    "def generate_with_backoff(client, batch_titles, retries=3):\n",
    "    \"\"\"Tries to generate content, retrying on 503 errors with exponential backoff.\"\"\"\n",
    "    prompt = f\"\"\"\n",
    "    You are an expert technical recruiter.\n",
    "    Generate a JSON List of objects for these job titles: {json.dumps(batch_titles)}\n",
    "    Follow this structure exactly:\n",
    "    {JSON_TEMPLATE}\n",
    "    Return ONLY valid JSON.\n",
    "    \"\"\"\n",
    "\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            response = client.models.generate_content(\n",
    "                model=\"gemini-2.5-flash\",\n",
    "                contents=prompt,\n",
    "                config={\"response_mime_type\": \"application/json\"}\n",
    "            )\n",
    "            return json.loads(clean_json_response(response.text))\n",
    "        except Exception as e:\n",
    "            wait_time = (2 ** attempt) + random.uniform(0, 1) # 1s, 2s, 4s...\n",
    "            print(f\"   ‚ö†Ô∏è Attempt {attempt+1} failed ({e}). Retrying in {wait_time:.1f}s...\")\n",
    "            time.sleep(wait_time)\n",
    "\n",
    "    print(f\"   ‚ùå Failed to generate batch {batch_titles} after {retries} attempts.\")\n",
    "    return []\n",
    "\n",
    "# --- 3. MAIN LOGIC ---\n",
    "\n",
    "def main():\n",
    "    # A. Load Existing Data\n",
    "    if os.path.exists(FILE_PATH):\n",
    "        try:\n",
    "            with open(FILE_PATH, \"r\") as f:\n",
    "                existing_data = json.load(f)\n",
    "            print(f\"üìÇ Loaded {len(existing_data)} existing roles from Drive.\")\n",
    "        except json.JSONDecodeError:\n",
    "            print(\"‚ö†Ô∏è Error reading existing file. Starting fresh.\")\n",
    "            existing_data = []\n",
    "    else:\n",
    "        print(\"üìÇ No existing file found. Starting fresh.\")\n",
    "        existing_data = []\n",
    "\n",
    "    # B. Identify Missing Categories\n",
    "    # We normalize to lowercase for comparison to avoid case-sensitivity issues\n",
    "    existing_titles = {item.get(\"job_title\", \"\").lower() for item in existing_data}\n",
    "\n",
    "    missing_categories = [\n",
    "        cat for cat in ALL_CATEGORIES\n",
    "        if cat.lower() not in existing_titles\n",
    "    ]\n",
    "\n",
    "    if not missing_categories:\n",
    "        print(\"‚úÖ All categories are already present! No action needed.\")\n",
    "        return\n",
    "\n",
    "    print(f\"üîç Found {len(missing_categories)} missing categories: {missing_categories}\")\n",
    "\n",
    "    # C. Initialize Client\n",
    "    try:\n",
    "        api_key = userdata.get('gemini_key')\n",
    "        client = genai.Client(api_key=api_key)\n",
    "    except Exception as e:\n",
    "        print(\"‚ùå API Key error.\")\n",
    "        return\n",
    "\n",
    "    # D. Generation Loop (Only for Missing)\n",
    "    BATCH_SIZE = 5 # Reduced batch size slightly for better stability on retry\n",
    "    new_data = []\n",
    "\n",
    "    for i in range(0, len(missing_categories), BATCH_SIZE):\n",
    "        batch = missing_categories[i : i + BATCH_SIZE]\n",
    "        print(f\"   Processing retry batch {i//BATCH_SIZE + 1}: {batch}\")\n",
    "\n",
    "        batch_result = generate_with_backoff(client, batch)\n",
    "\n",
    "        if batch_result:\n",
    "            new_data.extend(batch_result)\n",
    "            print(f\"   ‚úÖ Recovered {len(batch_result)} roles.\")\n",
    "\n",
    "        # Polite delay\n",
    "        time.sleep(2)\n",
    "\n",
    "    # E. Merge and Save\n",
    "    if new_data:\n",
    "        combined_data = existing_data + new_data\n",
    "\n",
    "        # Sort for neatness (optional)\n",
    "        combined_data.sort(key=lambda x: x.get(\"job_title\", \"\"))\n",
    "\n",
    "        with open(FILE_PATH, \"w\") as f:\n",
    "            json.dump(combined_data, f, indent=2)\n",
    "\n",
    "        print(f\"\\nüéâ Success! Added {len(new_data)} missing roles.\")\n",
    "        print(f\"üíæ Total roles in file: {len(combined_data)}\")\n",
    "        print(f\"üìÅ Updated file saved to: {FILE_PATH}\")\n",
    "    else:\n",
    "        print(\"\\n‚ö†Ô∏è No new data was generated during retry.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "aFW521buZVIH",
    "outputId": "36af3ac3-8252-4004-bf65-78468f53a984"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "files.download(FILE_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
